{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbaa6793",
   "metadata": {},
   "source": [
    "# computer vision\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3e7b5-bfa4-4e4d-9bbf-95a04ff5f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe6996-f27c-4ead-b9aa-61fa76443c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2\n",
      "torchvision version: 0.15.2a0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c06f8-e96c-435f-b8d6-4bc8453e2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fc857-7d4d-491f-8bda-5eadcc0dbbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70f4bd-942a-45b7-86f8-7eaf50e8f766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb455c-351b-43d4-b814-0c4ff84588fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "itost = {v:k for k, v in train_data.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840fcbb-84e6-4e6c-a532-0c8e546dd6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46034ccf-d797-4cb7-9062-cefb6b0196aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, l = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe2084-312d-4c60-b983-63d3b89f1443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d853d-3034-4a89-b3a5-f2853e3e7324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(itost[l])\n",
    "plt.imshow(i[0, :, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729df48-c2d9-4807-a4bd-efad070b151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object>, <torch.utils.data.dataloader.DataLoader object>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad888576-d338-4caf-a311-19a84796cbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0039, 0.0039,  ..., 0.0000, 0.0039, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0196, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0549,  ..., 0.0078, 0.0196, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0039, 0.0157,  ..., 0.0157, 0.0078, 0.0039]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2549, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3922, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0039, 0.0078,  ..., 0.0392, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),\n",
       " tensor([2, 6, 9, 7, 1, 2, 4, 0, 4, 2, 3, 4, 3, 0, 9, 1, 1, 1, 6, 8, 2, 2, 6, 2,\n",
       "         6, 2, 5, 9, 3, 9, 8, 6])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb46624-702c-4a9b-8d45-bf6983a4bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # flatten inputs into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850e4ff-e3ee-4ba0-bea6-116b1128a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae18c1f-b3af-41ce-854e-11c41d3398a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53444fc-a541-4b70-bbdb-681c50ad446f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784, # number of input features\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names) # number of output classes desired\n",
    ").to(device) # send model to GPU if it's available\n",
    "next(model_1.parameters()).device # check model device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8f74e-fca2-4e2a-a848-224151ea1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn_pytorch.helper import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30900ccf-7b1e-4f25-9e05-039ca6704939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf52256-0395-45ef-af4c-5a4fbffb8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7e859-9951-47ee-8750-8158965d5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format).\n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecf499-9228-4087-bb27-7cca6122c744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7bd0b0368547f9a8b38e3af62003e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 0.64506 | Train accuracy: 76.61%\n",
      "Test loss: 0.69396 | Test accuracy: 74.85%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 0.62733 | Train accuracy: 77.06%\n",
      "Test loss: 0.66595 | Test accuracy: 75.83%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 0.61514 | Train accuracy: 77.37%\n",
      "Test loss: 0.64979 | Test accuracy: 76.37%\n",
      "\n",
      "Train time on mps: 27.029 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b821f51-3c2c-41a4-bb1d-90ed3229233e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
