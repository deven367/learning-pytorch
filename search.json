[
  {
    "objectID": "03-cv.html",
    "href": "03-cv.html",
    "title": "computer vision",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\n# Import torchvision\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\n# Check versions\n# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\nprint(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n\nPyTorch version: 2.1.2\ntorchvision version: 0.15.2a0\n\n\n\n# Setup training data\ntrain_data = datasets.FashionMNIST(\n    root=\"data\", # where to download data to?\n    train=True, # get training data\n    download=True, # download data if it doesn't exist on disk\n    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n    target_transform=None # you can transform labels as well\n)\n\n# Setup testing data\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False, # get test data\n    download=True,\n    transform=ToTensor()\n)\n\n\ntrain_data.classes\n\n['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']\n\n\n\ntrain_data.class_to_idx\n\n{'T-shirt/top': 0,\n 'Trouser': 1,\n 'Pullover': 2,\n 'Dress': 3,\n 'Coat': 4,\n 'Sandal': 5,\n 'Shirt': 6,\n 'Sneaker': 7,\n 'Bag': 8,\n 'Ankle boot': 9}\n\n\n\nitost = {v:k for k, v in train_data.class_to_idx.items()}\n\n\ntrain_data.data.shape\n\ntorch.Size([60000, 28, 28])\n\n\n\ni, l = train_data[0]\n\n\ni.shape, l\n\n(torch.Size([1, 28, 28]), 9)\n\n\n\nplt.title(itost[l])\nplt.imshow(i[0, :, :]);\n\n\n\n\n\n\n\n\n\nfrom torch.utils.data import DataLoader\n\n# Setup the batch size hyperparameter\nBATCH_SIZE = 32\n\n# Turn datasets into iterables (batches)\ntrain_dataloader = DataLoader(train_data, # dataset to turn into iterable\n    batch_size=BATCH_SIZE, # how many samples per batch?\n    shuffle=True # shuffle data every epoch?\n)\n\ntest_dataloader = DataLoader(test_data,\n    batch_size=BATCH_SIZE,\n    shuffle=False # don't necessarily have to shuffle the testing data\n)\n\n# Let's check out what we've created\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object&gt;, &lt;torch.utils.data.dataloader.DataLoader object&gt;)\nLength of train dataloader: 1875 batches of 32\nLength of test dataloader: 313 batches of 32\n\n\n\nnext(iter(train_dataloader))\n\n[tensor([[[[0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n           [0.0000, 0.0039, 0.0039,  ..., 0.0000, 0.0039, 0.0000],\n           [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0196, 0.0000],\n           ...,\n           [0.0000, 0.0000, 0.0549,  ..., 0.0078, 0.0196, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0039, 0.0157,  ..., 0.0157, 0.0078, 0.0039]]],\n \n \n         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           ...,\n           [0.0000, 0.0000, 0.0000,  ..., 0.2549, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.3922, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n \n \n         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           ...,\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n \n \n         ...,\n \n \n         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           ...,\n           [0.0000, 0.0039, 0.0078,  ..., 0.0392, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n \n \n         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           ...,\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n \n \n         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           ...,\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),\n tensor([2, 6, 9, 7, 1, 2, 4, 0, 4, 2, 3, 4, 3, 0, 9, 1, 1, 1, 6, 8, 2, 2, 6, 2,\n         6, 2, 5, 9, 3, 9, 8, 6])]\n\n\n\n# Create a model with non-linear and linear layers\nclass FashionMNISTModelV1(nn.Module):\n    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n        super().__init__()\n        self.layer_stack = nn.Sequential(\n            nn.Flatten(), # flatten inputs into single vector\n            nn.Linear(in_features=input_shape, out_features=hidden_units),\n            nn.ReLU(),\n            nn.Linear(in_features=hidden_units, out_features=output_shape),\n            nn.ReLU()\n        )\n\n    def forward(self, x: torch.Tensor):\n        return self.layer_stack(x)\n\n\nclass_names = train_data.classes\n\n\ndevice = 'mps' if torch.backends.mps.is_available() else 'cpu'\n\n\ntorch.manual_seed(42)\nmodel_1 = FashionMNISTModelV1(input_shape=784, # number of input features\n    hidden_units=10,\n    output_shape=len(class_names) # number of output classes desired\n).to(device) # send model to GPU if it's available\nnext(model_1.parameters()).device # check model device\n\ndevice(type='mps', index=0)\n\n\n\nfrom learn_pytorch.helper import accuracy_fn\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(params=model_1.parameters(),\n                            lr=0.1)\n\n\ndef train_step(model: torch.nn.Module,\n               data_loader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               accuracy_fn,\n               device: torch.device = device):\n    train_loss, train_acc = 0, 0\n    model.to(device)\n    for batch, (X, y) in enumerate(data_loader):\n        # Send data to GPU\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss\n        train_acc += accuracy_fn(y_true=y,\n                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -&gt; pred labels\n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n    # Calculate loss and accuracy per epoch and print out what's happening\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n\ndef test_step(data_loader: torch.utils.data.DataLoader,\n              model: torch.nn.Module,\n              loss_fn: torch.nn.Module,\n              accuracy_fn,\n              device: torch.device = device):\n    test_loss, test_acc = 0, 0\n    model.to(device)\n    model.eval() # put model in eval mode\n    # Turn on inference context manager\n    with torch.inference_mode():\n        for X, y in data_loader:\n            # Send data to GPU\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred = model(X)\n\n            # 2. Calculate loss and accuracy\n            test_loss += loss_fn(test_pred, y)\n            test_acc += accuracy_fn(y_true=y,\n                y_pred=test_pred.argmax(dim=1) # Go from logits -&gt; pred labels\n            )\n\n        # Adjust metrics and print out\n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n\n\nfrom tqdm.notebook import tqdm\n\n\nfrom timeit import default_timer as timer\ndef print_train_time(start: float, end: float, device: torch.device = None):\n    \"\"\"Prints difference between start and end time.\n\n    Args:\n        start (float): Start time of computation (preferred in timeit format).\n        end (float): End time of computation.\n        device ([type], optional): Device that compute is running on. Defaults to None.\n\n    Returns:\n        float: time between start and end in seconds (higher is longer).\n    \"\"\"\n    total_time = end - start\n    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n    return total_time\n\n\ntorch.manual_seed(42)\n\n# Measure time\nfrom timeit import default_timer as timer\ntrain_time_start_on_gpu = timer()\n\nepochs = 3\nfor epoch in tqdm(range(epochs)):\n    print(f\"Epoch: {epoch}\\n---------\")\n    train_step(data_loader=train_dataloader,\n        model=model_1,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        accuracy_fn=accuracy_fn\n    )\n    test_step(data_loader=test_dataloader,\n        model=model_1,\n        loss_fn=loss_fn,\n        accuracy_fn=accuracy_fn\n    )\n\ntrain_time_end_on_gpu = timer()\ntotal_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n                                            end=train_time_end_on_gpu,\n                                            device=device)\n\n\n\n\nEpoch: 0\n---------\nTrain loss: 0.64506 | Train accuracy: 76.61%\nTest loss: 0.69396 | Test accuracy: 74.85%\n\nEpoch: 1\n---------\nTrain loss: 0.62733 | Train accuracy: 77.06%\nTest loss: 0.66595 | Test accuracy: 75.83%\n\nEpoch: 2\n---------\nTrain loss: 0.61514 | Train accuracy: 77.37%\nTest loss: 0.64979 | Test accuracy: 76.37%\n\nTrain time on mps: 27.029 seconds",
    "crumbs": [
      "computer vision"
    ]
  },
  {
    "objectID": "induction-head.html",
    "href": "induction-head.html",
    "title": "induction head",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass InductionHead(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(InductionHead, self).__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.qkv_proj = nn.Linear(embed_dim, 3 * embed_dim)  # Query, Key, Value projections\n        self.out_proj = nn.Linear(embed_dim, embed_dim)  # Output projection\n        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n\n    def forward(self, x):\n        # x shape: (seq_len, batch_size, embed_dim)\n        batch_size, seq_len, embed_dim = x.size()\n\n        # Project input to Q, K, V\n        qkv = self.qkv_proj(x)  # Shape: (seq_len, batch_size, 3 * embed_dim)\n        qkv = qkv.reshape(seq_len, batch_size, self.num_heads, 3 * embed_dim // self.num_heads)\n        qkv = qkv.permute(2, 1, 0, 3)  # (num_heads, batch_size, seq_len, 3 * embed_dim // num_heads)\n        Q, K, V = qkv.chunk(3, dim=-1)  # Split into Q, K, V\n\n        # Compute attention\n        attn_output, attn_weights = self.attention(Q, K, V)\n\n        # Concatenate heads\n        attn_output = attn_output.permute(1, 0, 2).contiguous().reshape(batch_size, seq_len, embed_dim)\n\n        # Output projection\n        output = self.out_proj(attn_output)\n        return output, attn_weights\n\n\nclass InductionHead(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(InductionHead, self).__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.qkv_proj = nn.Linear(embed_dim, 3 * embed_dim)  # Query, Key, Value projections\n        self.out_proj = nn.Linear(embed_dim, embed_dim)  # Output projection\n        self.attention = nn.MultiheadAttention(embed_dim, num_heads)\n\n    def forward(self, x):\n        # x shape: (seq_len, batch_size, embed_dim)\n        seq_len, batch_size, embed_dim = x.size()\n\n        # Project input to Q, K, V\n        qkv = self.qkv_proj(x)  # Shape: (seq_len, batch_size, 3 * embed_dim)\n        qkv = qkv.reshape(seq_len, batch_size, 3, self.num_heads, embed_dim // self.num_heads)\n        qkv = qkv.permute(2, 3, 1, 0, 4)  # (3, num_heads, batch_size, seq_len, embed_dim_per_head)\n        Q, K, V = qkv[0], qkv[1], qkv[2]  # Split into Q, K, V\n\n        # Reshape Q, K, V for attention mechanism\n        # Q = Q.reshape(batch_size * self.num_heads, seq_len, embed_dim // self.num_heads)\n        # K = K.reshape(batch_size * self.num_heads, seq_len, embed_dim // self.num_heads)\n        # V = V.reshape(batch_size * self.num_heads, seq_len, embed_dim // self.num_heads)\n\n        Q = Q.reshape(batch_size * self.num_heads, seq_len, embed_dim )\n        K = K.reshape(batch_size * self.num_heads, seq_len, embed_dim )\n        V = V.reshape(batch_size * self.num_heads, seq_len, embed_dim )\n\n        # Apply attention (query, key, value)\n        attn_output, attn_weights = self.attention(Q, K, V)\n\n        # Reshape attention output back\n        attn_output = attn_output.reshape(batch_size, self.num_heads, seq_len, embed_dim // self.num_heads)\n        attn_output = attn_output.permute(2, 0, 1, 3).reshape(seq_len, batch_size, embed_dim)\n\n        # Output projection\n        output = self.out_proj(attn_output)\n        return output, attn_weights\n\n\n# Example usage:\nembed_dim = 512\nnum_heads = 8\ninduction_head = InductionHead(embed_dim, num_heads)\n\n\n# Dummy input (batch_size, seq_len, embed_dim)\nx = torch.randn(10, 20, embed_dim)\noutput, attn_weights = induction_head(x)\nprint(output.shape)  # Expected: (batch_size, seq_len, embed_dim)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[11], line 3\n      1 # Dummy input (batch_size, seq_len, embed_dim)\n      2 x = torch.randn(10, 20, embed_dim)\n----&gt; 3 output, attn_weights = induction_head(x)\n      4 print(output.shape)  # Expected: (batch_size, seq_len, embed_dim)\n\nFile ~/miniforge3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1530     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1531 else:\n-&gt; 1532     return self._call_impl(*args, **kwargs)\n\nFile ~/miniforge3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541, in Module._call_impl(self, *args, **kwargs)\n   1536 # If we don't have any hooks, we want to skip the rest of the logic in\n   1537 # this function, and just call forward.\n   1538 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1539         or _global_backward_pre_hooks or _global_backward_hooks\n   1540         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1541     return forward_call(*args, **kwargs)\n   1543 try:\n   1544     result = None\n\nCell In[9], line 25, in InductionHead.forward(self, x)\n     18 Q, K, V = qkv[0], qkv[1], qkv[2]  # Split into Q, K, V\n     20 # Reshape Q, K, V for attention mechanism\n     21 # Q = Q.reshape(batch_size * self.num_heads, seq_len, embed_dim // self.num_heads)\n     22 # K = K.reshape(batch_size * self.num_heads, seq_len, embed_dim // self.num_heads)\n     23 # V = V.reshape(batch_size * self.num_heads, seq_len, embed_dim // self.num_heads)\n---&gt; 25 Q = Q.reshape(batch_size * self.num_heads, seq_len, embed_dim )\n     26 K = K.reshape(batch_size * self.num_heads, seq_len, embed_dim )\n     27 V = V.reshape(batch_size * self.num_heads, seq_len, embed_dim )\n\nRuntimeError: shape '[160, 10, 512]' is invalid for input of size 102400\n\n\n\n\nx.device\n\ndevice(type='cpu')",
    "crumbs": [
      "induction head"
    ]
  },
  {
    "objectID": "00-fundamentals.html",
    "href": "00-fundamentals.html",
    "title": "fundamentals",
    "section": "",
    "text": "!which python\n\n/Users/deven367/mambaforge/envs/pth/bin/python\n!pip show torch\n\nName: torch\nVersion: 2.0.1\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3\nLocation: /Users/deven367/mambaforge/envs/pth/lib/python3.10/site-packages\nRequires: filelock, jinja2, networkx, sympy, typing-extensions\nRequired-by: accelerate, fastai, peft, torchaudio, torchvision\nimport torch\ntorch.__version__\n\n'2.0.1'",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#scalar",
    "href": "00-fundamentals.html#scalar",
    "title": "fundamentals",
    "section": "scalar",
    "text": "scalar\n\n# Scalar\nscalar = torch.tensor(7)\nscalar\n\ntensor(7)\n\n\n\nscalar.item()\n\n7\n\n\n\nscalar.ndim\n\n0",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#vector",
    "href": "00-fundamentals.html#vector",
    "title": "fundamentals",
    "section": "vector",
    "text": "vector\n\nvector = torch.tensor([1, 2])\nvector\n\ntensor([1, 2])",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#matrix",
    "href": "00-fundamentals.html#matrix",
    "title": "fundamentals",
    "section": "matrix",
    "text": "matrix\n\n# Matrix\nMATRIX = torch.tensor([[7, 8],\n                       [9, 10]])\nMATRIX\n\ntensor([[ 7,  8],\n        [ 9, 10]])\n\n\n\nMATRIX.ndim\n\n2",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#tensor",
    "href": "00-fundamentals.html#tensor",
    "title": "fundamentals",
    "section": "tensor",
    "text": "tensor\n\n# Tensor\nTENSOR = torch.tensor([[[1, 2, 3],\n                        [3, 6, 9],\n                        [2, 4, 5]]])\nTENSOR\n\ntensor([[[1, 2, 3],\n         [3, 6, 9],\n         [2, 4, 5]]])\n\n\n\nTENSOR.shape\n\ntorch.Size([1, 3, 3])",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#random-tensor",
    "href": "00-fundamentals.html#random-tensor",
    "title": "fundamentals",
    "section": "random tensor",
    "text": "random tensor\n\nx = torch.rand(size=(3,4))\n\n\nx, x.dtype\n\n(tensor([[0.0054, 0.3713, 0.6901, 0.3464],\n         [0.7347, 0.2866, 0.8748, 0.8203],\n         [0.8466, 0.4066, 0.3717, 0.1785]]),\n torch.float32)\n\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.imshow(x)\n\n\n\n\n\n\n\n\n\nx3 = torch.rand(size=(3, 500, 500))\nx3\n\ntensor([[[0.3124, 0.2393, 0.6851,  ..., 0.5956, 0.0522, 0.9978],\n         [0.4588, 0.5240, 0.2963,  ..., 0.2372, 0.2270, 0.9578],\n         [0.6997, 0.8471, 0.7639,  ..., 0.1464, 0.2590, 0.8607],\n         ...,\n         [0.6741, 0.5199, 0.0177,  ..., 0.9062, 0.1984, 0.2768],\n         [0.8433, 0.9803, 0.4615,  ..., 0.7602, 0.1122, 0.0832],\n         [0.9944, 0.1375, 0.7048,  ..., 0.8367, 0.4785, 0.7167]],\n\n        [[0.3095, 0.4969, 0.4572,  ..., 0.4483, 0.9172, 0.3245],\n         [0.6805, 0.3055, 0.0011,  ..., 0.0420, 0.0053, 0.6516],\n         [0.2692, 0.3799, 0.4305,  ..., 0.9412, 0.0964, 0.4699],\n         ...,\n         [0.8962, 0.6808, 0.7867,  ..., 0.7209, 0.0227, 0.6804],\n         [0.8378, 0.6278, 0.9680,  ..., 0.2193, 0.5567, 0.7397],\n         [0.6402, 0.2966, 0.7525,  ..., 0.3614, 0.1355, 0.9917]],\n\n        [[0.5723, 0.2855, 0.3038,  ..., 0.4785, 0.7347, 0.5672],\n         [0.3403, 0.0803, 0.9781,  ..., 0.9861, 0.6144, 0.2424],\n         [0.1284, 0.1958, 0.3418,  ..., 0.3563, 0.6601, 0.2327],\n         ...,\n         [0.2266, 0.1774, 0.5236,  ..., 0.0964, 0.6774, 0.3021],\n         [0.5507, 0.0731, 0.5770,  ..., 0.0038, 0.2636, 0.4521],\n         [0.0790, 0.1722, 0.8542,  ..., 0.2528, 0.7655, 0.9268]]])\n\n\n\nx3.T.shape\n\n/var/folders/83/lj3mdwvd2s12wl1q96t6lkvr0000gn/T/ipykernel_7615/3902085171.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686130/work/aten/src/ATen/native/TensorShape.cpp:3575.)\n  x3.T.shape\n\n\ntorch.Size([500, 500, 3])\n\n\n\nplt.imshow(x3.T);",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#tensor-manipulation",
    "href": "00-fundamentals.html#tensor-manipulation",
    "title": "fundamentals",
    "section": "tensor manipulation",
    "text": "tensor manipulation\n\nTENSOR, TENSOR.dtype\n\n(tensor([[[1, 2, 3],\n          [3, 6, 9],\n          [2, 4, 5]]]),\n torch.int64)\n\n\n\nTENSOR + 10\n\ntensor([[[11, 12, 13],\n         [13, 16, 19],\n         [12, 14, 15]]])\n\n\n\nTENSOR * 10\n\ntensor([[[10, 20, 30],\n         [30, 60, 90],\n         [20, 40, 50]]])\n\n\n\ntf = torch.tensor([[[1, 2, 3],\n                    [3, 6, 9],\n                    [2, 4, 5]]], dtype = torch.float32)\n\n\nTENSOR * tf\n\ntensor([[[ 1.,  4.,  9.],\n         [ 9., 36., 81.],\n         [ 4., 16., 25.]]])",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#linear-layer",
    "href": "00-fundamentals.html#linear-layer",
    "title": "fundamentals",
    "section": "linear layer",
    "text": "linear layer\n\ntorch.manual_seed(42)\n\n&lt;torch._C.Generator&gt;\n\n\n\nl1 = torch.nn.Linear(2, 10)\n\n\nl1(torch.tensor([1., 1.]))\n\ntensor([ 0.8017,  0.4010, -0.2994,  0.5401, -0.4536,  0.4210,  0.4185, -0.1840,\n         0.7164, -0.8483], grad_fn=&lt;AddBackward0&gt;)\n\n\n\ntt = torch.tensor([[[1., 2.]]])\ntt, tt.shape\n\n(tensor([[[1., 2.]]]), torch.Size([1, 1, 2]))\n\n\n\ntorch.squeeze(tt), torch.squeeze(tt).shape\n\n(tensor([1., 2.]), torch.Size([2]))",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "00-fundamentals.html#cuda-check",
    "href": "00-fundamentals.html#cuda-check",
    "title": "fundamentals",
    "section": "cuda check",
    "text": "cuda check\n\ntorch.cuda.is_available()\n\nFalse",
    "crumbs": [
      "fundamentals"
    ]
  },
  {
    "objectID": "micrograd_lecture_second_half_roughly.html",
    "href": "micrograd_lecture_second_half_roughly.html",
    "title": "micrograd - part 2",
    "section": "",
    "text": "import math\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef f(x):\n  return 3*x**2 - 4*x + 5\n\n\nf(3.0)\n\n20.0\n\n\n\nxs = np.arange(-5, 5, 0.25)\nys = f(xs)\nplt.plot(xs, ys)\n\n\n\n\n\n\n\n\n\nh = 0.000001\nx = 2/3\n(f(x + h) - f(x))/h\n\n2.999378523327323e-06\n\n\n\n# les get more complex\na = 2.0\nb = -3.0\nc = 10.0\nd = a*b + c\nprint(d)\n\n4.0\n\n\n\nh = 0.0001\n\n# inputs\na = 2.0\nb = -3.0\nc = 10.0\n\nd1 = a*b + c\nc += h\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2 - d1)/h)\n\nd1 4.0\nd2 4.0001\nslope 0.9999999999976694\n\n\n\nclass Value:\n\n  def __init__(self, data, _children=(), _op='', label=''):\n    self.data = data\n    self.grad = 0.0\n    self._backward = lambda: None\n    self._prev = set(_children)\n    self._op = _op\n    self.label = label\n\n  def __repr__(self):\n    return f\"Value(data={self.data})\"\n\n  def __add__(self, other):\n    other = other if isinstance(other, Value) else Value(other)\n    out = Value(self.data + other.data, (self, other), '+')\n\n    def _backward():\n      self.grad += 1.0 * out.grad\n      other.grad += 1.0 * out.grad\n    out._backward = _backward\n\n    return out\n\n  def __mul__(self, other):\n    other = other if isinstance(other, Value) else Value(other)\n    out = Value(self.data * other.data, (self, other), '*')\n\n    def _backward():\n      self.grad += other.data * out.grad\n      other.grad += self.data * out.grad\n    out._backward = _backward\n\n    return out\n\n  def __pow__(self, other):\n    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n    out = Value(self.data**other, (self,), f'**{other}')\n\n    def _backward():\n        self.grad += other * (self.data ** (other - 1)) * out.grad\n    out._backward = _backward\n\n    return out\n\n  def __rmul__(self, other): # other * self\n    return self * other\n\n  def __truediv__(self, other): # self / other\n    return self * other**-1\n\n  def __neg__(self): # -self\n    return self * -1\n\n  def __sub__(self, other): # self - other\n    return self + (-other)\n\n  def __radd__(self, other): # other + self\n    return self + other\n\n  def tanh(self):\n    x = self.data\n    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n    out = Value(t, (self, ), 'tanh')\n\n    def _backward():\n      self.grad += (1 - t**2) * out.grad\n    out._backward = _backward\n\n    return out\n\n  def exp(self):\n    x = self.data\n    out = Value(math.exp(x), (self, ), 'exp')\n\n    def _backward():\n      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n    out._backward = _backward\n\n    return out\n\n\n  def backward(self):\n\n    topo = []\n    visited = set()\n    def build_topo(v):\n      if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n          build_topo(child)\n        topo.append(v)\n    build_topo(self)\n\n    self.grad = 1.0\n    for node in reversed(topo):\n      node._backward()\n\n\nfrom graphviz import Digraph\n\ndef trace(root):\n  # builds a set of all nodes and edges in a graph\n  nodes, edges = set(), set()\n  def build(v):\n    if v not in nodes:\n      nodes.add(v)\n      for child in v._prev:\n        edges.add((child, v))\n        build(child)\n  build(root)\n  return nodes, edges\n\ndef draw_dot(root):\n  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n\n  nodes, edges = trace(root)\n  for n in nodes:\n    uid = str(id(n))\n    # for any value in the graph, create a rectangular ('record') node for it\n    dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n    if n._op:\n      # if this value is a result of some operation, create an op node for it\n      dot.node(name = uid + n._op, label = n._op)\n      # and connect this node to it\n      dot.edge(uid + n._op, uid)\n\n  for n1, n2 in edges:\n    # connect n1 to the op node of n2\n    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n\n  return dot\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\no.backward()\n\n\ndraw_dot(o)\n\n\n\n\n\n\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n# ----\ne = (2*n).exp()\no = (e - 1) / (e + 1)\n# ----\no.label = 'o'\no.backward()\ndraw_dot(o)\n\n\n\n\n\n\n\n\n\nimport torch\n\n\nx1 = torch.Tensor([2.0]).double()                ; x1.requires_grad = True\nx2 = torch.Tensor([0.0]).double()                ; x2.requires_grad = True\nw1 = torch.Tensor([-3.0]).double()               ; w1.requires_grad = True\nw2 = torch.Tensor([1.0]).double()                ; w2.requires_grad = True\nb = torch.Tensor([6.8813735870195432]).double()  ; b.requires_grad = True\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\nprint(o.data.item())\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n\n\n\nclass Neuron:\n\n  def __init__(self, nin):\n    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n    self.b = Value(random.uniform(-1,1))\n\n  def __call__(self, x):\n    # w * x + b\n    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n    out = act.tanh()\n    return out\n\n  def parameters(self):\n    return self.w + [self.b]\n\nclass Layer:\n\n  def __init__(self, nin, nout):\n    self.neurons = [Neuron(nin) for _ in range(nout)]\n\n  def __call__(self, x):\n    outs = [n(x) for n in self.neurons]\n    return outs[0] if len(outs) == 1 else outs\n\n  def parameters(self):\n    return [p for neuron in self.neurons for p in neuron.parameters()]\n\nclass MLP:\n\n  def __init__(self, nin, nouts):\n    sz = [nin] + nouts\n    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n\n  def __call__(self, x):\n    for layer in self.layers:\n      x = layer(x)\n    return x\n\n  def parameters(self):\n    return [p for layer in self.layers for p in layer.parameters()]\n\n\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n\nValue(data=0.40638197915146174)\n\n\n\nxs = [\n  [2.0, 3.0, -1.0],\n  [3.0, -1.0, 0.5],\n  [0.5, 1.0, 1.0],\n  [1.0, 1.0, -1.0],\n]\nys = [1.0, -1.0, -1.0, 1.0] # desired targets\n\n\nfor k in range(20):\n\n  # forward pass\n  ypred = [n(x) for x in xs]\n  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n\n  # backward pass\n  for p in n.parameters():\n    p.grad = 0.0\n  loss.backward()\n\n  # update\n  for p in n.parameters():\n    p.data += -0.1 * p.grad\n\n  print(k, loss.data)\n\n0 3.4108119643530888\n1 2.7333908126990187\n2 2.529685744713404\n3 1.5991660472245495\n4 1.8519402770590592\n5 0.32191773394239787\n6 0.037788868223750174\n7 0.03252592980059902\n8 0.028743826618205327\n9 0.02584982329406658\n10 0.02353984318126514\n11 0.0216396514140169\n12 0.020041077243779393\n13 0.018672744820048957\n14 0.017485253063873017\n15 0.01644307646812274\n16 0.015519858571980637\n17 0.014695534862119995\n18 0.01395449758312289\n19 0.01328438199165979\n\n\n\nypred\n\n[Value(data=0.94354238926853),\n Value(data=-0.9432664093982158),\n Value(data=-0.9493416317799401),\n Value(data=0.9343345630573925)]",
    "crumbs": [
      "micrograd - part 2"
    ]
  },
  {
    "objectID": "01-workflows.html",
    "href": "01-workflows.html",
    "title": "workflows",
    "section": "",
    "text": "import torch\nfrom torch import nn # nn contains all of PyTorch's building blocks for neural networks\nimport matplotlib.pyplot as plt\n\n# Check PyTorch version\ntorch.__version__\n\n'2.1.0+cu121'\n\n\n\n# Create *known* parameters\nweight = 0.7\nbias = 0.3\n\n# Create data\nstart = 0\nend = 1\nstep = 0.02\nX = torch.arange(start, end, step).unsqueeze(dim=1)\ny = weight * X + bias\n\nX[:10], y[:10]\n\n(tensor([[0.0000],\n         [0.0200],\n         [0.0400],\n         [0.0600],\n         [0.0800],\n         [0.1000],\n         [0.1200],\n         [0.1400],\n         [0.1600],\n         [0.1800]]),\n tensor([[0.3000],\n         [0.3140],\n         [0.3280],\n         [0.3420],\n         [0.3560],\n         [0.3700],\n         [0.3840],\n         [0.3980],\n         [0.4120],\n         [0.4260]]))\n\n\n\nX.shape, y.shape\n\n(torch.Size([50, 1]), torch.Size([50, 1]))\n\n\n\n# Create train/test split\ntrain_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\nX_train, y_train = X[:train_split], y[:train_split]\nX_test, y_test = X[train_split:], y[train_split:]\n\nlen(X_train), len(y_train), len(X_test), len(y_test)\n\n(40, 40, 10, 10)\n\n\n\ndef plot_predictions(train_data=X_train,\n                     train_labels=y_train,\n                     test_data=X_test,\n                     test_labels=y_test,\n                     predictions=None):\n  \"\"\"\n  Plots training data, test data and compares predictions.\n  \"\"\"\n  plt.figure(figsize=(10, 7))\n\n  # Plot training data in blue\n  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n\n  # Plot test data in green\n  plt.scatter(test_data, test_labels, c=\"orange\", s=4, label=\"Testing data\")\n\n  if predictions is not None:\n    # Plot the predictions in red (predictions were made on the test data)\n    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n\n  # Show the legend\n  plt.legend(prop={\"size\": 14});\n\n\nplot_predictions();\n\n\n\n\n\n\n\n\n\nclass Linear(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.weights = nn.Parameter(torch.rand(1, requires_grad=True))\n        self.bias = nn.Parameter(torch.rand(1, requires_grad=True))\n\n    def forward(self, x):\n        return self.weights * x + self.bias\n\n\n# Set manual seed since nn.Parameter are randomly initialzied\ntorch.manual_seed(42)\n\n# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n# model_0 = LinearModel()\nmodel_0 = Linear()\n\n# Check the nn.Parameter(s) within the nn.Module subclass we created\nlist(model_0.parameters())\n\n[Parameter containing:\n tensor([0.8823], requires_grad=True),\n Parameter containing:\n tensor([0.9150], requires_grad=True)]\n\n\n\n# List named parameters\nmodel_0.state_dict()\n\nOrderedDict([('weights', tensor([0.8823])), ('bias', tensor([0.9150]))])\n\n\n\nwith torch.inference_mode():\n    preds = model_0(X_test)\n\n\nplot_predictions(predictions=preds)\n\n\n\n\n\n\n\n\n\n# Create the loss function\nloss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n\n# Create the optimizer\noptimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, higher=more (less stable), lower=less (might take a long time))\n\n\ntorch.manual_seed(42)\n\n# Set the number of epochs (how many times the model will pass over the training data)\nepochs = 100\n\n# Create empty loss lists to track values\ntrain_loss_values = []\ntest_loss_values = []\nepoch_count = []\n\nfor epoch in range(epochs):\n    ### Training\n\n    # Put model in training mode (this is the default state of a model)\n    model_0.train()\n\n    # 1. Forward pass on train data using the forward() method inside\n    y_pred = model_0(X_train)\n    # print(y_pred)\n\n    # 2. Calculate the loss (how different are our models predictions to the ground truth)\n    loss = loss_fn(y_pred, y_train)\n\n    # 3. Zero grad of the optimizer\n    optimizer.zero_grad()\n\n    # 4. Loss backwards\n    loss.backward()\n\n    # 5. Progress the optimizer\n    optimizer.step()\n\n    ### Testing\n\n    # Put the model in evaluation mode\n    model_0.eval()\n\n    with torch.inference_mode():\n      # 1. Forward pass on test data\n      test_pred = model_0(X_test)\n\n      # 2. Caculate loss on test data\n      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n\n      # Print out what's happening\n      if epoch % 10 == 0:\n            epoch_count.append(epoch)\n            train_loss_values.append(loss.detach().numpy())\n            test_loss_values.append(test_loss.detach().numpy())\n            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n\nEpoch: 0 | MAE Train Loss: 0.6860889196395874 | MAE Test Loss: 0.7637526988983154 \nEpoch: 10 | MAE Train Loss: 0.5708791017532349 | MAE Test Loss: 0.6290428042411804 \nEpoch: 20 | MAE Train Loss: 0.45566922426223755 | MAE Test Loss: 0.4943329691886902 \nEpoch: 30 | MAE Train Loss: 0.34045934677124023 | MAE Test Loss: 0.35962313413619995 \nEpoch: 40 | MAE Train Loss: 0.2252494841814041 | MAE Test Loss: 0.2249133139848709 \nEpoch: 50 | MAE Train Loss: 0.1100396141409874 | MAE Test Loss: 0.09020347893238068 \nEpoch: 60 | MAE Train Loss: 0.009724985808134079 | MAE Test Loss: 0.020998019725084305 \nEpoch: 70 | MAE Train Loss: 0.006216754671186209 | MAE Test Loss: 0.014099234715104103 \nEpoch: 80 | MAE Train Loss: 0.002788322512060404 | MAE Test Loss: 0.005826681852340698 \nEpoch: 90 | MAE Train Loss: 0.007095950655639172 | MAE Test Loss: 0.00754010071977973 \n\n\n\nnew_preds = model_0(X_test)\n\n\nnew_preds\n\ntensor([[0.8661],\n        [0.8801],\n        [0.8940],\n        [0.9080],\n        [0.9220],\n        [0.9359],\n        [0.9499],\n        [0.9638],\n        [0.9778],\n        [0.9917]], grad_fn=&lt;AddBackward0&gt;)\n\n\nYou can’t plot a differentiable tensor.\n\ntry: plt.plot(new_preds)\nexcept Exception as e: print(e)\n\nCan't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n\n\n\n\n\n\n\n\n\n\np = new_preds.detach().numpy()\n\n\nplot_predictions(predictions=p)\n\n\n\n\n\n\n\n\n\nfrom pathlib import Path\n\n# 1. Create models directory\nMODEL_PATH = Path(\"models\")\nMODEL_PATH.mkdir(parents=True, exist_ok=True)\n\n# 2. Create model save path\nMODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\nMODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n\n# 3. Save the model state dict\nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters\n           f=MODEL_SAVE_PATH)\n\nSaving model to: models/01_pytorch_workflow_model_0.pth\n\n\n\ntorch.load(MODEL_SAVE_PATH)\n\nOrderedDict([('weights', tensor([0.6977])), ('bias', tensor([0.3080]))])\n\n\n\nsave_model = Linear()\nsave_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n\n&lt;All keys matched successfully&gt;\n\n\n\nsave_model(X_test)\n\ntensor([[0.8661],\n        [0.8801],\n        [0.8940],\n        [0.9080],\n        [0.9220],\n        [0.9359],\n        [0.9499],\n        [0.9638],\n        [0.9778],\n        [0.9917]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nX_test.shape\n\ntorch.Size([10, 1])\n\n\nYou can practically use any shape tensor for prediction as in the forward pass, you only multiply it with a scalar and then add one. Due to operator broadcasting, you won’t face any shape mismatch errors.\n\nsave_model(torch.rand((10, 9)))\n\ntensor([[0.7863, 0.9844, 0.6076, 0.6541, 0.5765, 0.3656, 0.8242, 0.3105, 0.8734],\n        [0.9178, 0.9867, 0.5746, 0.3702, 0.7353, 0.8495, 0.3096, 0.5777, 0.4477],\n        [0.6263, 0.4851, 0.5142, 0.5461, 0.3253, 0.9431, 0.9493, 0.6021, 0.6171],\n        [0.5145, 0.3418, 0.3174, 0.7865, 0.4653, 0.4326, 0.6296, 0.5407, 0.5440],\n        [0.6680, 0.5828, 0.5367, 0.4898, 0.3729, 0.9493, 0.5172, 0.7493, 0.5358],\n        [0.6852, 0.9821, 0.8176, 0.3545, 0.7953, 0.9880, 0.7486, 0.8907, 1.0008],\n        [0.6034, 0.7292, 0.4144, 0.5850, 0.9152, 0.8357, 0.4361, 0.3771, 0.4185],\n        [0.3126, 0.3877, 0.5706, 0.8923, 0.7152, 0.3915, 0.3770, 0.8304, 0.3974],\n        [0.6139, 0.8242, 0.4954, 0.6188, 0.6265, 0.5743, 0.4800, 0.3459, 0.3749],\n        [0.4701, 0.9938, 0.4883, 0.4226, 0.7414, 0.7530, 0.8480, 0.9220, 0.8511]],\n       grad_fn=&lt;AddBackward0&gt;)",
    "crumbs": [
      "workflows"
    ]
  },
  {
    "objectID": "micrograd.html",
    "href": "micrograd.html",
    "title": "micrograd",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n\ndef f(x):\n    return 3*x**2 - 4*x + 5\n\n\nf(3.)\n\n20.0\n\n\n\nfrom graphviz import Digraph\n\ndef trace(root):\n    nodes, edges = set(), set()\n    def build(v):\n        if v not in nodes:\n            nodes.add(v)\n            for child in v._prev:\n                edges.add((child, v))\n                build(child)\n    build(root)\n    return nodes, edges\n\ndef draw_dot(root, format='svg', rankdir='LR'):\n    \"\"\"\n    format: png | svg | ...\n    rankdir: TB (top to bottom graph) | LR (left to right)\n    \"\"\"\n    assert rankdir in ['LR', 'TB']\n    nodes, edges = trace(root)\n    dot = Digraph(format=format, graph_attr={'rankdir': rankdir}) #, node_attr={'rankdir': 'TB'})\n\n    for n in nodes:\n        uid = str(id(n))\n        dot.node(name=uid, label = \"{ %s | data %.4f | grad %.4f}\" % (n.label, n.data, n.grad), shape='record')\n        if n._op:\n            dot.node(name=str(id(n)) + n._op, label=n._op)\n            dot.edge(str(id(n)) + n._op, str(id(n)))\n\n    for n1, n2 in edges:\n        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n\n    return dot\n\n\nclass Value:\n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self.grad = 0.0\n        self._backward = lambda: None\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        \n        def _backward():\n            self.grad += 1.0 * out.grad\n            other.grad += 1.0 * out.grad\n        \n        out._backward = _backward\n            \n        return out\n\n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n        \n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        \n        out._backward = _backward\n        \n        return out\n\n    def __rmul__(self, other): # other * self\n        return self * other\n\n    def __truediv__(self, other): # self / other\n        return self * other**-1\n\n    def __neg__(self): # -self\n        return self * -1\n\n    def __sub__(self, other): # self - other\n        return self + (-other)\n\n    def __radd__(self, other): # other + self\n        return self + other\n    \n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data ** other, (self, ), f'**other')\n        \n        def _backward():\n            self.grad += (other * out.data**(other-1)) * out.grad\n        \n        out._backward = _backward\n        return out\n    \n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n        out = Value(t, (self, ), 'tanh')\n        \n        def _backward():\n            self.grad += (1 - t**2) * out.grad\n            \n        out._backward = _backward\n        return out\n    \n    def exp(self):\n        x = self.data\n        out = Value(math.exp(x), (self, ), 'exp')\n        \n        def _backward():\n            self.grad += out.data * out.grad\n        \n        out._backward = _backward\n        return out\n    \n    def backward(self):\n    \n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        build_topo(self)\n\n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n\n\na = Value(2., label = 'a')\nb = Value(-3., label = 'b')\nc = Value(10., label = 'c')\ne = a*b; e.label = 'e'\nd = e + c; d.label = 'd'\nf = Value(-2., label='f')\nL = d * f; L.label = 'L'\nL\n\nValue(data=-8.0)\n\n\n\nValue(1) +  2\n\nValue(data=3)\n\n\n\ndef lol():\n\n    h = 0.001\n\n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label='f')\n    L = d * f; L.label = 'L'\n    L1 = L.data\n\n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    b.data += h\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label='f')\n    L = d * f; L.label = 'L'\n    L2 = L.data\n\n    print((L2 - L1)/h)\n\nlol()\n\n-3.9999999999995595\n\n\n\nd._prev, d._op\n\n({Value(data=-6.0), Value(data=10.0)}, '+')\n\n\n\nL.grad = 1.\nf.grad = 4.\nd.grad = -2\n\n\nc.grad = -2.\ne.grad = -2.\n\n\na.grad = 6.\nb.grad = -4.\n\n\ndraw_dot(L)\n\n\n\n\n\n\n\n\n\nplt.plot(np.arange(-5,5,0.2), np.tanh(np.arange(-5,5,0.2))); plt.grid();\n\n\n\n\n\n\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\n\n\ndraw_dot(o)\n\n\n\n\n\n\n\n\n\no.backward()\n\n\na = Value(3.0, label='b')\nb = a + a; b.label = 'b'\nb.backward()\ndraw_dot(b)\n\n\n\n\n\n\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n# weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n# x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n# ----\ne = (2*n).exp()\no = (e - 1) / (e + 1)\n# ----\no.label = 'o'\no.backward()\ndraw_dot(o)\n\n\n\n\n\n\n\n\n\n(2*n).exp()\n\nValue(data=5.828427124746192)\n\n\n\nValue(10)**2\n\nValue(data=100)\n\n\n\nimport torch\n\n\nx1 = torch.Tensor([2.0]).double()                ; x1.requires_grad = True\nx2 = torch.Tensor([0.0]).double()                ; x2.requires_grad = True\nw1 = torch.Tensor([-3.0]).double()               ; w1.requires_grad = True\nw2 = torch.Tensor([1.0]).double()                ; w2.requires_grad = True\nb = torch.Tensor([6.8813735870195432]).double()  ; b.requires_grad = True\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\nprint(o.data.item())\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n\n\n\no.data\n\ntensor([0.7071], dtype=torch.float64)\n\n\n\nimport random\n\n\nclass Neuron:\n  \n  def __init__(self, nin):\n    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n    self.b = Value(random.uniform(-1,1))\n  \n  def __call__(self, x):\n    # w * x + b\n    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n    out = act.tanh()\n    return out\n  \n  def parameters(self):\n    return self.w + [self.b]\n\nclass Layer:\n  \n  def __init__(self, nin, nout):\n    self.neurons = [Neuron(nin) for _ in range(nout)]\n  \n  def __call__(self, x):\n    outs = [n(x) for n in self.neurons]\n    return outs[0] if len(outs) == 1 else outs\n  \n  def parameters(self):\n    return [p for neuron in self.neurons for p in neuron.parameters()]\n\nclass MLP:\n  \n  def __init__(self, nin, nouts):\n    sz = [nin] + nouts\n    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n  \n  def __call__(self, x):\n    for layer in self.layers:\n      x = layer(x)\n    return x\n  def parameters(self):\n    return [p for layer in self.layers for p in layer.parameters()]\n\n\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n\nValue(data=-0.8518646845522475)\n\n\n\nlen(n.parameters())\n\n41\n\n\n\nxs = [\n  [2.0, 3.0, -1.0],\n  [3.0, -1.0, 0.5],\n  [0.5, 1.0, 1.0],\n  [1.0, 1.0, -1.0],\n]\nys = [1.0, -1.0, -1.0, 1.0] # desired targets\n\n\nypred = [n(x) for x in xs]\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n\nValue(data=8.195423138300107)\n\n\n\nypred = [n(x) for x in xs]\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n\nValue(data=8.195423138300107)\n\n\n\nloss.backward()\n\n\nfor p in n.parameters():\n    p.data += -0.01 * p.grad\n\n\nypred\n\n[Value(data=-0.8518646845522475),\n Value(data=0.12883393385135233),\n Value(data=-0.5205839755359478),\n Value(data=-0.8060771173128451)]\n\n\n\nfor k in range(200):\n  \n  # forward pass\n  ypred = [n(x) for x in xs]\n  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n  \n  # backward pass\n  for p in n.parameters():\n    p.grad = 0.0\n  \n  loss.backward()\n  \n  # update\n  for p in n.parameters():\n    p.data += -0.1 * p.grad\n  \n  print(k, loss.data)\n\n0 7.9987601054344974\n1 7.998768254319929\n2 7.998776289198453\n3 7.998784212518286\n4 7.998792026656887\n5 7.998799733923519\n6 7.998807336561709\n7 7.99881483675159\n8 7.998822236612142\n9 7.9988295382033545\n10 7.998836743528274\n11 7.998843854534988\n12 7.99885087311851\n13 7.998857801122596\n14 7.9988646403414805\n15 7.998871392521546\n16 7.99887805936293\n17 7.998884642521051\n18 7.998891143608089\n19 7.998897564194406\n20 7.998903905809901\n21 7.998910169945322\n22 7.998916358053519\n23 7.998922471550658\n24 7.998928511817379\n25 7.998934480199918\n26 7.99894037801118\n27 7.998946206531777\n28 7.9989519670110205\n29 7.998957660667887\n30 7.998963288691943\n31 7.998968852244227\n32 7.998974352458117\n33 7.998979790440156\n34 7.998985167270847\n35 7.998990484005422\n36 7.998995741674587\n37 7.999000941285239\n38 7.999006083821148\n39 7.999011170243634\n40 7.9990162014922035\n41 7.999021178485171\n42 7.999026102120268\n43 7.999030973275209\n44 7.999035792808263\n45 7.999040561558786\n46 7.999045280347749\n47 7.999049949978248\n48 7.99905457123598\n49 7.999059144889733\n50 7.999063671691822\n51 7.999068152378555\n52 7.999072587670647\n53 7.999076978273633\n54 7.999081324878281\n55 7.9990856281609695\n56 7.99908988878407\n57 7.999094107396307\n58 7.9990982846331145\n59 7.999102421116978\n60 7.999106517457763\n61 7.999110574253039\n62 7.9991145920883895\n63 7.999118571537715\n64 7.999122513163526\n65 7.999126417517225\n66 7.999130285139385\n67 7.999134116560015\n68 7.999137912298817\n69 7.999141672865441\n70 7.999145398759733\n71 7.99914909047196\n72 7.999152748483052\n73 7.999156373264821\n74 7.999159965280181\n75 7.999163524983352\n76 7.99916705282007\n77 7.999170549227792\n78 7.999174014635873\n79 7.9991774494657735\n80 7.999180854131225\n81 7.999184229038425\n82 7.999187574586189\n83 7.999190891166139\n84 7.999194179162857\n85 7.99919743895404\n86 7.999200670910663\n87 7.999203875397127\n88 7.999207052771402\n89 7.999210203385175\n90 7.999213327583982\n91 7.999216425707352\n92 7.999219498088927\n93 7.999222545056597\n94 7.999225566932631\n95 7.999228564033784\n96 7.999231536671427\n97 7.9992344851516535\n98 7.9992374097753975\n99 7.999240310838541\n100 7.999243188632027\n101 7.999246043441947\n102 7.999248875549657\n103 7.999251685231876\n104 7.9992544727607715\n105 7.999257238404061\n106 7.999259982425107\n107 7.9992627050829945\n108 7.999265406632628\n109 7.99926808732482\n110 7.999270747406354\n111 7.99927338712009\n112 7.999276006705024\n113 7.999278606396377\n114 7.999281186425669\n115 7.99928374702078\n116 7.999286288406042\n117 7.999288810802287\n118 7.999291314426934\n119 7.999293799494042\n120 7.999296266214385\n121 7.999298714795511\n122 7.999301145441796\n123 7.999303558354529\n124 7.999305953731936\n125 7.99930833176927\n126 7.999310692658851\n127 7.999313036590123\n128 7.99931536374971\n129 7.999317674321473\n130 7.999319968486549\n131 7.999322246423416\n132 7.999324508307934\n133 7.999326754313392\n134 7.999328984610566\n135 7.999331199367747\n136 7.999333398750801\n137 7.999335582923215\n138 7.99933775204612\n139 7.999339906278356\n140 7.999342045776506\n141 7.9993441706949255\n142 7.999346281185799\n143 7.999348377399164\n144 7.99935045948296\n145 7.99935252758306\n146 7.999354581843308\n147 7.999356622405555\n148 7.999358649409688\n149 7.999360662993675\n150 7.999362663293588\n151 7.999364650443644\n152 7.999366624576229\n153 7.9993685858219346\n154 7.9993705343095876\n155 7.9993724701662785\n156 7.9993743935173915\n157 7.999376304486636\n158 7.999378203196072\n159 7.9993800897661345\n160 7.999381964315667\n161 7.9993838269619495\n162 7.999385677820711\n163 7.99938751700617\n164 7.999389344631057\n165 7.999391160806628\n166 7.999392965642702\n167 7.999394759247677\n168 7.999396541728552\n169 7.999398313190958\n170 7.999400073739171\n171 7.999401823476137\n172 7.999403562503496\n173 7.999405290921597\n174 7.999407008829529\n175 7.999408716325124\n176 7.999410413504997\n177 7.999412100464545\n178 7.999413777297985\n179 7.999415444098361\n180 7.999417100957562\n181 7.9994187479663506\n182 7.999420385214364\n183 7.999422012790147\n184 7.9994236307811555\n185 7.999425239273788\n186 7.99942683835339\n187 7.99942842810427\n188 7.999430008609728\n189 7.999431579952053\n190 7.999433142212552\n191 7.9994346954715585\n192 7.999436239808448\n193 7.999437775301655\n194 7.999439302028684\n195 7.999440820066123\n196 7.999442329489664\n197 7.999443830374101\n198 7.999445322793363\n199 7.99944680682051",
    "crumbs": [
      "micrograd"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "learn-pytorch",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "learn-pytorch"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "learn-pytorch",
    "section": "Install",
    "text": "Install\npip install learn_pytorch",
    "crumbs": [
      "learn-pytorch"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "learn-pytorch",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "learn-pytorch"
    ]
  },
  {
    "objectID": "02-nn-classification.html",
    "href": "02-nn-classification.html",
    "title": "nn classification",
    "section": "",
    "text": "from sklearn.datasets import make_circles\nimport matplotlib.pyplot as plt\n\n# Make 1000 samples\nn_samples = 1000\n\n# Create circles\nX, y = make_circles(n_samples,\n                    noise=0.03, # a little bit of noise to the dots\n                    random_state=42) # keep random state so we get the same values\n\n\nplt.scatter(x=X[:, 0],\n            y=X[:, 1],\n            c=y,\n            cmap=plt.cm.RdYlBu);\n\n\n\n\n\n\n\n\n\nX = torch.from_numpy(X).type(torch.float)\ny = torch.from_numpy(y).type(torch.float)\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nX_train.shape\n\ntorch.Size([800, 2])\n\n\n2 linear layers without a non-linearity can’t solve this problem.\n\nclass CircleClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.Linear(2, 10)\n        self.l2 = nn.Linear(10, 1)\n    def forward(self, x):\n        return self.l2(self.l1(x))\n\n\nclass CircleClassifierImproved(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.Linear(2, 10)\n        self.l2 = nn.Linear(10, 10)\n        self.l3 = nn.Linear(10, 1)\n        self.relu = nn.ReLU()\n    def forward(self, x):\n        x = self.l1(x)\n        x = self.relu(x)\n\n        x = self.l2(x)\n        x = self.relu(x)\n\n        x = self.l3(x)\n        # x = self.relu(x)\n\n        return x\n        # return self.l3(self.relu(self.l2(self.relu(self.l1(x)))))\n\n\nnn.BCEWithLogitsLoss()\n\nBCEWithLogitsLoss()\n\n\n\nt = torch.from_numpy(X_train.numpy()).type(torch.float32)\n\n\nt\n\ntensor([[ 0.6579, -0.4651],\n        [ 0.6319, -0.7347],\n        [-1.0086, -0.1240],\n        ...,\n        [ 0.0157, -1.0300],\n        [ 1.0110,  0.1680],\n        [ 0.5578, -0.5709]])\n\n\nHalf is float16, Float is float32\n\nf = nn.Linear(2, 10)(t)\n\n\nnn.Linear(2, 10)(t).shape\n\ntorch.Size([800, 10])\n\n\n\n# c = CircleClassifier()\nc = CircleClassifierImproved()\n\n\nc.parameters\n\n&lt;bound method Module.parameters of CircleClassifierImproved(\n  (l1): Linear(in_features=2, out_features=10, bias=True)\n  (l2): Linear(in_features=10, out_features=10, bias=True)\n  (l3): Linear(in_features=10, out_features=1, bias=True)\n  (relu): ReLU()\n)&gt;\n\n\n\nloss_fn = nn.BCEWithLogitsLoss()\nopt = torch.optim.Adam(c.parameters(), lr=0.01)\n\n\ntr_loss = []\nvl_loss = []\n\n\nsource\n\naccuracy_fn\n\n accuracy_fn (y_true, y_pred)\n\n\n# training loop\nfor epoch in range(100):\n    c.train()\n\n    y_pred = c(X_train).squeeze()\n    act_pred = torch.sigmoid(y_pred).round()\n    loss = loss_fn(y_pred, y_train)\n\n    tr_loss.append(loss.detach().numpy())\n    acc = accuracy_fn(y_train, act_pred)\n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n\n    c.eval()\n    with torch.inference_mode():\n        v_pred = c(X_test).squeeze()\n        act_pred = torch.sigmoid(v_pred).round()\n        vloss = loss_fn(v_pred, y_test)\n        vl_loss.append(vloss.detach().numpy())\n        test_acc = accuracy_fn(y_test, act_pred)\n    print(f\"Epoch: {epoch+1:&gt;5} | Loss: {tr_loss[epoch]:.5f}, Accuracy: {acc:.2f}% | Test loss: {vl_loss[epoch]:.5f}, Test acc: {test_acc:.2f}%\")\n\nEpoch:     1 | Loss: 0.70613, Accuracy: 50.00% | Test loss: 0.69981, Test acc: 50.00%\nEpoch:     2 | Loss: 0.70133, Accuracy: 50.00% | Test loss: 0.69647, Test acc: 50.00%\nEpoch:     3 | Loss: 0.69771, Accuracy: 50.00% | Test loss: 0.69404, Test acc: 50.00%\nEpoch:     4 | Loss: 0.69492, Accuracy: 50.00% | Test loss: 0.69286, Test acc: 50.00%\nEpoch:     5 | Loss: 0.69331, Accuracy: 50.00% | Test loss: 0.69212, Test acc: 50.00%\nEpoch:     6 | Loss: 0.69220, Accuracy: 50.00% | Test loss: 0.69157, Test acc: 50.00%\nEpoch:     7 | Loss: 0.69131, Accuracy: 50.00% | Test loss: 0.69106, Test acc: 53.50%\nEpoch:     8 | Loss: 0.69054, Accuracy: 54.00% | Test loss: 0.69053, Test acc: 67.00%\nEpoch:     9 | Loss: 0.68979, Accuracy: 65.50% | Test loss: 0.69007, Test acc: 57.00%\nEpoch:    10 | Loss: 0.68913, Accuracy: 58.75% | Test loss: 0.68970, Test acc: 64.00%\nEpoch:    11 | Loss: 0.68858, Accuracy: 72.50% | Test loss: 0.68941, Test acc: 60.50%\nEpoch:    12 | Loss: 0.68814, Accuracy: 64.50% | Test loss: 0.68914, Test acc: 53.50%\nEpoch:    13 | Loss: 0.68769, Accuracy: 56.75% | Test loss: 0.68883, Test acc: 50.50%\nEpoch:    14 | Loss: 0.68720, Accuracy: 54.00% | Test loss: 0.68849, Test acc: 50.50%\nEpoch:    15 | Loss: 0.68668, Accuracy: 54.12% | Test loss: 0.68817, Test acc: 50.00%\nEpoch:    16 | Loss: 0.68615, Accuracy: 54.00% | Test loss: 0.68778, Test acc: 50.50%\nEpoch:    17 | Loss: 0.68555, Accuracy: 53.87% | Test loss: 0.68733, Test acc: 51.00%\nEpoch:    18 | Loss: 0.68484, Accuracy: 54.50% | Test loss: 0.68681, Test acc: 51.00%\nEpoch:    19 | Loss: 0.68404, Accuracy: 56.00% | Test loss: 0.68626, Test acc: 58.50%\nEpoch:    20 | Loss: 0.68318, Accuracy: 57.75% | Test loss: 0.68567, Test acc: 66.50%\nEpoch:    21 | Loss: 0.68227, Accuracy: 67.75% | Test loss: 0.68502, Test acc: 67.50%\nEpoch:    22 | Loss: 0.68128, Accuracy: 70.62% | Test loss: 0.68428, Test acc: 68.00%\nEpoch:    23 | Loss: 0.68020, Accuracy: 74.12% | Test loss: 0.68347, Test acc: 69.00%\nEpoch:    24 | Loss: 0.67901, Accuracy: 75.25% | Test loss: 0.68258, Test acc: 69.50%\nEpoch:    25 | Loss: 0.67770, Accuracy: 75.75% | Test loss: 0.68157, Test acc: 67.50%\nEpoch:    26 | Loss: 0.67626, Accuracy: 74.88% | Test loss: 0.68043, Test acc: 66.50%\nEpoch:    27 | Loss: 0.67467, Accuracy: 74.62% | Test loss: 0.67915, Test acc: 66.50%\nEpoch:    28 | Loss: 0.67293, Accuracy: 74.88% | Test loss: 0.67771, Test acc: 67.50%\nEpoch:    29 | Loss: 0.67104, Accuracy: 75.75% | Test loss: 0.67609, Test acc: 72.00%\nEpoch:    30 | Loss: 0.66899, Accuracy: 77.25% | Test loss: 0.67429, Test acc: 74.00%\nEpoch:    31 | Loss: 0.66681, Accuracy: 79.12% | Test loss: 0.67234, Test acc: 73.00%\nEpoch:    32 | Loss: 0.66447, Accuracy: 80.88% | Test loss: 0.67003, Test acc: 75.00%\nEpoch:    33 | Loss: 0.66187, Accuracy: 82.62% | Test loss: 0.66745, Test acc: 77.50%\nEpoch:    34 | Loss: 0.65910, Accuracy: 83.88% | Test loss: 0.66471, Test acc: 79.50%\nEpoch:    35 | Loss: 0.65609, Accuracy: 84.50% | Test loss: 0.66191, Test acc: 81.50%\nEpoch:    36 | Loss: 0.65286, Accuracy: 84.75% | Test loss: 0.65893, Test acc: 81.00%\nEpoch:    37 | Loss: 0.64938, Accuracy: 84.50% | Test loss: 0.65574, Test acc: 81.50%\nEpoch:    38 | Loss: 0.64567, Accuracy: 83.75% | Test loss: 0.65231, Test acc: 81.50%\nEpoch:    39 | Loss: 0.64171, Accuracy: 84.00% | Test loss: 0.64861, Test acc: 81.50%\nEpoch:    40 | Loss: 0.63742, Accuracy: 84.25% | Test loss: 0.64470, Test acc: 82.50%\nEpoch:    41 | Loss: 0.63276, Accuracy: 85.00% | Test loss: 0.64057, Test acc: 83.00%\nEpoch:    42 | Loss: 0.62778, Accuracy: 85.25% | Test loss: 0.63625, Test acc: 84.00%\nEpoch:    43 | Loss: 0.62252, Accuracy: 85.88% | Test loss: 0.63162, Test acc: 84.00%\nEpoch:    44 | Loss: 0.61692, Accuracy: 86.38% | Test loss: 0.62664, Test acc: 83.00%\nEpoch:    45 | Loss: 0.61092, Accuracy: 86.88% | Test loss: 0.62134, Test acc: 82.50%\nEpoch:    46 | Loss: 0.60456, Accuracy: 87.38% | Test loss: 0.61568, Test acc: 82.00%\nEpoch:    47 | Loss: 0.59790, Accuracy: 87.62% | Test loss: 0.60965, Test acc: 82.00%\nEpoch:    48 | Loss: 0.59087, Accuracy: 88.38% | Test loss: 0.60335, Test acc: 84.00%\nEpoch:    49 | Loss: 0.58350, Accuracy: 88.88% | Test loss: 0.59668, Test acc: 86.00%\nEpoch:    50 | Loss: 0.57580, Accuracy: 89.88% | Test loss: 0.58967, Test acc: 86.00%\nEpoch:    51 | Loss: 0.56766, Accuracy: 89.88% | Test loss: 0.58240, Test acc: 85.50%\nEpoch:    52 | Loss: 0.55916, Accuracy: 90.38% | Test loss: 0.57505, Test acc: 86.00%\nEpoch:    53 | Loss: 0.55035, Accuracy: 90.38% | Test loss: 0.56752, Test acc: 86.50%\nEpoch:    54 | Loss: 0.54119, Accuracy: 90.75% | Test loss: 0.55975, Test acc: 86.50%\nEpoch:    55 | Loss: 0.53172, Accuracy: 91.12% | Test loss: 0.55162, Test acc: 87.50%\nEpoch:    56 | Loss: 0.52195, Accuracy: 91.25% | Test loss: 0.54284, Test acc: 88.00%\nEpoch:    57 | Loss: 0.51186, Accuracy: 91.50% | Test loss: 0.53345, Test acc: 89.50%\nEpoch:    58 | Loss: 0.50148, Accuracy: 93.00% | Test loss: 0.52359, Test acc: 89.50%\nEpoch:    59 | Loss: 0.49084, Accuracy: 93.50% | Test loss: 0.51348, Test acc: 90.50%\nEpoch:    60 | Loss: 0.47999, Accuracy: 94.25% | Test loss: 0.50321, Test acc: 90.50%\nEpoch:    61 | Loss: 0.46889, Accuracy: 94.62% | Test loss: 0.49286, Test acc: 91.50%\nEpoch:    62 | Loss: 0.45752, Accuracy: 95.00% | Test loss: 0.48230, Test acc: 92.50%\nEpoch:    63 | Loss: 0.44594, Accuracy: 95.38% | Test loss: 0.47142, Test acc: 93.00%\nEpoch:    64 | Loss: 0.43416, Accuracy: 96.12% | Test loss: 0.45992, Test acc: 93.50%\nEpoch:    65 | Loss: 0.42218, Accuracy: 96.50% | Test loss: 0.44792, Test acc: 94.00%\nEpoch:    66 | Loss: 0.41001, Accuracy: 97.00% | Test loss: 0.43578, Test acc: 94.50%\nEpoch:    67 | Loss: 0.39774, Accuracy: 97.50% | Test loss: 0.42370, Test acc: 94.50%\nEpoch:    68 | Loss: 0.38530, Accuracy: 97.88% | Test loss: 0.41170, Test acc: 95.00%\nEpoch:    69 | Loss: 0.37275, Accuracy: 98.38% | Test loss: 0.40001, Test acc: 95.00%\nEpoch:    70 | Loss: 0.36025, Accuracy: 98.62% | Test loss: 0.38800, Test acc: 95.00%\nEpoch:    71 | Loss: 0.34785, Accuracy: 99.25% | Test loss: 0.37590, Test acc: 96.00%\nEpoch:    72 | Loss: 0.33540, Accuracy: 99.38% | Test loss: 0.36391, Test acc: 95.50%\nEpoch:    73 | Loss: 0.32299, Accuracy: 99.62% | Test loss: 0.35204, Test acc: 95.50%\nEpoch:    74 | Loss: 0.31074, Accuracy: 99.50% | Test loss: 0.34034, Test acc: 95.50%\nEpoch:    75 | Loss: 0.29863, Accuracy: 99.62% | Test loss: 0.32815, Test acc: 96.50%\nEpoch:    76 | Loss: 0.28671, Accuracy: 99.62% | Test loss: 0.31684, Test acc: 97.00%\nEpoch:    77 | Loss: 0.27495, Accuracy: 99.75% | Test loss: 0.30451, Test acc: 96.50%\nEpoch:    78 | Loss: 0.26350, Accuracy: 99.75% | Test loss: 0.29342, Test acc: 97.00%\nEpoch:    79 | Loss: 0.25207, Accuracy: 99.75% | Test loss: 0.28239, Test acc: 97.50%\nEpoch:    80 | Loss: 0.24108, Accuracy: 99.75% | Test loss: 0.27058, Test acc: 96.50%\nEpoch:    81 | Loss: 0.23057, Accuracy: 99.75% | Test loss: 0.26014, Test acc: 98.00%\nEpoch:    82 | Loss: 0.22004, Accuracy: 99.88% | Test loss: 0.24962, Test acc: 98.00%\nEpoch:    83 | Loss: 0.20993, Accuracy: 99.88% | Test loss: 0.23933, Test acc: 98.50%\nEpoch:    84 | Loss: 0.20031, Accuracy: 99.75% | Test loss: 0.23038, Test acc: 98.50%\nEpoch:    85 | Loss: 0.19090, Accuracy: 100.00% | Test loss: 0.22084, Test acc: 99.00%\nEpoch:    86 | Loss: 0.18199, Accuracy: 100.00% | Test loss: 0.21133, Test acc: 99.00%\nEpoch:    87 | Loss: 0.17354, Accuracy: 99.88% | Test loss: 0.20343, Test acc: 99.00%\nEpoch:    88 | Loss: 0.16532, Accuracy: 100.00% | Test loss: 0.19521, Test acc: 99.00%\nEpoch:    89 | Loss: 0.15748, Accuracy: 100.00% | Test loss: 0.18683, Test acc: 99.00%\nEpoch:    90 | Loss: 0.15006, Accuracy: 100.00% | Test loss: 0.17948, Test acc: 99.00%\nEpoch:    91 | Loss: 0.14285, Accuracy: 100.00% | Test loss: 0.17194, Test acc: 99.00%\nEpoch:    92 | Loss: 0.13596, Accuracy: 100.00% | Test loss: 0.16453, Test acc: 99.00%\nEpoch:    93 | Loss: 0.12921, Accuracy: 100.00% | Test loss: 0.15815, Test acc: 99.00%\nEpoch:    94 | Loss: 0.12239, Accuracy: 100.00% | Test loss: 0.15175, Test acc: 99.00%\nEpoch:    95 | Loss: 0.11617, Accuracy: 100.00% | Test loss: 0.14526, Test acc: 99.00%\nEpoch:    96 | Loss: 0.11073, Accuracy: 100.00% | Test loss: 0.13985, Test acc: 99.00%\nEpoch:    97 | Loss: 0.10570, Accuracy: 100.00% | Test loss: 0.13480, Test acc: 99.00%\nEpoch:    98 | Loss: 0.10094, Accuracy: 100.00% | Test loss: 0.12950, Test acc: 99.00%\nEpoch:    99 | Loss: 0.09646, Accuracy: 100.00% | Test loss: 0.12458, Test acc: 99.00%\nEpoch:   100 | Loss: 0.09219, Accuracy: 100.00% | Test loss: 0.11975, Test acc: 99.00%\n\n\n\nplt.plot(tr_loss)\nplt.plot(vl_loss);",
    "crumbs": [
      "nn classification"
    ]
  },
  {
    "objectID": "hook.html",
    "href": "hook.html",
    "title": "learning-pytorch",
    "section": "",
    "text": "from transformer_lens import utils\nfrom transformer_lens import HookedTransformer\n\n\n\nmodel = HookedTransformer.from_pretrained('gpt2')\n\nLoaded pretrained model gpt2 into HookedTransformer\n\n\n\ndef example_hook(attention_scores, hook):\n    layer = hook.layer()\n    print(f\"{layer=} {hook.name=}\")\n    return attention_scores\n\n\nmodel\n\nHookedTransformer(\n  (embed): Embed()\n  (hook_embed): HookPoint()\n  (pos_embed): PosEmbed()\n  (hook_pos_embed): HookPoint()\n  (blocks): ModuleList(\n    (0-11): 12 x TransformerBlock(\n      (ln1): LayerNormPre(\n        (hook_scale): HookPoint()\n        (hook_normalized): HookPoint()\n      )\n      (ln2): LayerNormPre(\n        (hook_scale): HookPoint()\n        (hook_normalized): HookPoint()\n      )\n      (attn): Attention(\n        (hook_k): HookPoint()\n        (hook_q): HookPoint()\n        (hook_v): HookPoint()\n        (hook_z): HookPoint()\n        (hook_attn_scores): HookPoint()\n        (hook_pattern): HookPoint()\n        (hook_result): HookPoint()\n      )\n      (mlp): MLP(\n        (hook_pre): HookPoint()\n        (hook_post): HookPoint()\n      )\n      (hook_attn_in): HookPoint()\n      (hook_q_input): HookPoint()\n      (hook_k_input): HookPoint()\n      (hook_v_input): HookPoint()\n      (hook_mlp_in): HookPoint()\n      (hook_attn_out): HookPoint()\n      (hook_mlp_out): HookPoint()\n      (hook_resid_pre): HookPoint()\n      (hook_resid_mid): HookPoint()\n      (hook_resid_post): HookPoint()\n    )\n  )\n  (ln_final): LayerNormPre(\n    (hook_scale): HookPoint()\n    (hook_normalized): HookPoint()\n  )\n  (unembed): Unembed()\n)\n\n\n\nwith model.hooks([(utils.get_act_name('pattern', 0), example_hook)]):\n    model('this is a test')\n\nlayer=0 hook.name='blocks.0.attn.hook_pattern'",
    "crumbs": [
      "hook.html"
    ]
  },
  {
    "objectID": "attention.html",
    "href": "attention.html",
    "title": "attention",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nsentence = \"life is short eat dessert first\"\nd = {v:k for k, v in enumerate(sorted(sentence.split()))}\nd\n\n{'dessert': 0, 'eat': 1, 'first': 2, 'is': 3, 'life': 4, 'short': 5}\nsentence_int = torch.tensor([d[s] for s in sentence.split()])\nsentence_int\n\ntensor([4, 3, 5, 1, 0, 2])",
    "crumbs": [
      "attention"
    ]
  },
  {
    "objectID": "attention.html#embedding",
    "href": "attention.html#embedding",
    "title": "attention",
    "section": "embedding",
    "text": "embedding\n\ntorch.manual_seed(367)\nembed = nn.Embedding(6, 16)\n\n\nembed.weight\n\nParameter containing:\ntensor([[-0.6464,  0.1896, -0.1400, -0.5293,  2.2280, -0.5509,  0.8565,  0.6965,\n          0.2921,  0.7246, -0.2228,  0.1755,  0.3178, -0.8774,  1.1153, -0.8318],\n        [ 0.3682,  0.0866,  0.4898, -0.6596,  0.5912, -1.3599,  0.2875, -0.3362,\n          0.0528,  0.5361, -0.6639, -0.0485, -0.1884, -1.0605,  0.7885,  0.8130],\n        [-1.1571, -0.4416, -0.2310, -0.3186,  0.7454, -0.5900, -0.2848,  0.8694,\n         -0.3333, -2.3269, -2.6385, -1.5790,  0.3806,  0.3829, -0.6320, -1.1084],\n        [-0.6519, -0.6055,  0.2631, -0.6609,  1.1417, -0.0193, -0.7428, -1.4321,\n         -0.0080,  0.4575,  0.8962,  0.0268,  0.1488, -0.7864,  0.4031,  0.8617],\n        [ 0.3572,  1.1703,  0.2762,  1.9486,  0.0347, -0.9270,  0.4420,  0.0789,\n          0.7242,  1.1438,  1.2067,  1.5952,  0.8898, -0.3228,  0.4987, -0.3865],\n        [ 0.1276,  2.2140,  1.5148, -0.0443,  0.9131, -0.6947,  0.2029,  1.3926,\n         -0.7305, -0.4706, -0.0121, -0.4266, -0.2352, -0.6012, -0.9594,  0.5300]],\n       requires_grad=True)\n\n\n\nsentence_int\n\ntensor([4, 3, 5, 1, 0, 2])\n\n\n\nembedded_sentence = embed(sentence_int)",
    "crumbs": [
      "attention"
    ]
  },
  {
    "objectID": "attention.html#sdpa",
    "href": "attention.html#sdpa",
    "title": "attention",
    "section": "sdpa",
    "text": "sdpa\n\nnn.Parameter(torch.rand(3,3))\n\nParameter containing:\ntensor([[0.0373, 0.4159, 0.8324],\n        [0.7977, 0.4048, 0.0143],\n        [0.4707, 0.9528, 0.2652]], requires_grad=True)\n\n\n\nnn.Linear(3,3).weight\n\nParameter containing:\ntensor([[ 0.5657,  0.5205, -0.0074],\n        [-0.4242, -0.3910, -0.0658],\n        [-0.2243, -0.1632,  0.2622]], requires_grad=True)\n\n\n\ndim_model = embedded_sentence.shape[1]\n\nd_q = 24\nd_k = 24\nd_v = 28",
    "crumbs": [
      "attention"
    ]
  }
]